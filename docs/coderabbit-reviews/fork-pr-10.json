[
  {
    "id": 3661367246,
    "node_id": "PRR_kwDOQ5BBoM7aPAfO",
    "user": {
      "login": "coderabbitai[bot]",
      "id": 136622811,
      "node_id": "BOT_kgDOCCSy2w",
      "avatar_url": "https://avatars.githubusercontent.com/in/347564?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/coderabbitai%5Bbot%5D",
      "html_url": "https://github.com/apps/coderabbitai",
      "followers_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/coderabbitai%5Bbot%5D/received_events",
      "type": "Bot",
      "user_view_type": "public",
      "site_admin": false
    },
    "body": "**Actionable comments posted: 1**\n\n<details>\n<summary>ü§ñ Fix all issues with AI agents</summary>\n\n```\nIn `@opc/scripts/core/db/embedding_service.py`:\n- Around line 459-460: The code silently falls back to 768 when a model key is\nmissing from MODELS (self._dimension = self.MODELS.get(self.model, 768)), which\ncan hide mismatches; change the initialization to check if self.model is in\nself.MODELS and if not set self._dimension to the fallback but emit a warning\nthat includes the requested model name and the fallback dimension (use the\nexisting logger instance or module logger), e.g., detect \"if self.model not in\nself.MODELS: self._dimension = 768; logger.warning(...)\" otherwise use the value\nfrom MODELS.\n```\n\n</details>\n\n<details>\n<summary>üßπ Nitpick comments (2)</summary><blockquote>\n\n<details>\n<summary>opc/scripts/core/db/embedding_service.py (2)</summary><blockquote>\n\n`462-470`: **Missing retry logic for transient failures.**\n\nUnlike `OpenAIEmbeddingProvider` and `VoyageEmbeddingProvider` which implement retry with exponential backoff, `OllamaEmbeddingProvider.embed()` has no retry logic. Network hiccups or temporary Ollama server unavailability will immediately fail.\n\n\n\n<details>\n<summary>‚ôªÔ∏è Suggested implementation with retry</summary>\n\n```diff\n+    DEFAULT_MAX_RETRIES = 3\n+    RETRY_DELAY = 0.5\n+\n+    def __init__(\n+        self,\n+        model: str | None = None,\n+        host: str | None = None,\n+        verify_ssl: bool | None = None,\n+        max_retries: int = DEFAULT_MAX_RETRIES,\n+    ):\n         ...\n+        self.max_retries = max_retries\n\n     async def embed(self, text: str) -> list[float]:\n         \"\"\"Generate embedding for a single text.\"\"\"\n+        import asyncio\n+        last_error: Exception | None = None\n         url = f\"{self.host.rstrip('/')}/api/embeddings\"\n-        response = await self._client.post(url, json={\"model\": self.model, \"prompt\": text})\n-        response.raise_for_status()\n-        data = response.json()\n-        if \"embedding\" not in data:\n-            raise EmbeddingError(f\"Ollama response missing 'embedding' field: {data}\")\n-        return data[\"embedding\"]\n+        for attempt in range(self.max_retries):\n+            try:\n+                response = await self._client.post(url, json={\"model\": self.model, \"prompt\": text})\n+                response.raise_for_status()\n+                data = response.json()\n+                if \"embedding\" not in data:\n+                    raise EmbeddingError(f\"Ollama response missing 'embedding' field: {data}\")\n+                return data[\"embedding\"]\n+            except Exception as e:\n+                last_error = e\n+                if attempt < self.max_retries - 1:\n+                    await asyncio.sleep(self.RETRY_DELAY * (attempt + 1))\n+        raise EmbeddingError(f\"Ollama API call failed after {self.max_retries} attempts: {last_error}\")\n```\n</details>\n\n---\n\n`480-488`: **Missing async context manager methods for consistency.**\n\n`OpenAIEmbeddingProvider` and `VoyageEmbeddingProvider` implement `__aenter__`/`__aexit__` for use as async context managers. Adding these to `OllamaEmbeddingProvider` would maintain consistency and allow standalone usage with `async with`.\n\n\n\n<details>\n<summary>‚ôªÔ∏è Add context manager support</summary>\n\n```diff\n     async def aclose(self) -> None:\n         \"\"\"Close the HTTP client.\"\"\"\n         await self._client.aclose()\n\n+    async def __aenter__(self) -> \"OllamaEmbeddingProvider\":\n+        \"\"\"Enter async context manager.\"\"\"\n+        return self\n+\n+    async def __aexit__(self, *args) -> None:\n+        \"\"\"Exit async context manager and close client.\"\"\"\n+        await self.aclose()\n+\n     `@property`\n     def dimension(self) -> int:\n```\n</details>\n\n</blockquote></details>\n\n</blockquote></details>\n\n<details>\n<summary>üìú Review details</summary>\n\n**Configuration used**: Path: .coderabbit.yaml\n\n**Review profile**: CHILL\n\n**Plan**: Pro\n\n<details>\n<summary>üì• Commits</summary>\n\nReviewing files that changed from the base of the PR and between 2e2e2cf81db9df95c2147c7f2c3eda6dea45976e and 42975f82f087e8b55625df6ff268a9f7664cfc94.\n\n</details>\n\n<details>\n<summary>üìí Files selected for processing (5)</summary>\n\n* `.coderabbit.yaml`\n* `opc/pyproject.toml`\n* `opc/scripts/core/db/embedding_service.py`\n* `opc/scripts/core/store_learning.py`\n* `opc/scripts/setup/wizard.py`\n\n</details>\n\n<details>\n<summary>üß∞ Additional context used</summary>\n\n<details>\n<summary>üß¨ Code graph analysis (1)</summary>\n\n<details>\n<summary>opc/scripts/core/store_learning.py (1)</summary><blockquote>\n\n<details>\n<summary>opc/scripts/core/db/embedding_service.py (5)</summary>\n\n* `EmbeddingService` (553-738)\n* `aclose` (106-108)\n* `aclose` (254-256)\n* `aclose` (480-482)\n* `aclose` (727-730)\n\n</details>\n\n</blockquote></details>\n\n</details>\n\n</details>\n\n<details>\n<summary>üîá Additional comments (11)</summary><blockquote>\n\n<details>\n<summary>opc/pyproject.toml (2)</summary><blockquote>\n\n`44-47`: **LGTM!**\n\nGood documentation explaining the backward compatibility reason for keeping the empty group.\n\n---\n\n`36-37`: **Installation footprint impact of moving embedding dependencies.**\n\nMoving `sentence-transformers` and `torch` to main dependencies significantly increases the installation footprint for all users (~2-3GB). Consider whether this is the desired behavior or if optional dependencies would be more appropriate.\n\n\n\n> Likely an incorrect or invalid review comment.\n\n</blockquote></details>\n<details>\n<summary>opc/scripts/core/store_learning.py (4)</summary><blockquote>\n\n`117-127`: **LGTM!**\n\nGood resource management pattern‚Äîinitializing to `None` before the try block ensures the finally clause can safely check and clean up resources regardless of where an exception occurs.\n\n---\n\n`179-183`: **LGTM!**\n\nProper cleanup in the finally block ensures embedder and memory resources are released even when exceptions occur.\n\n---\n\n`249-259`: **LGTM!**\n\nConsistent application of the same resource management pattern as `store_learning_v2`.\n\n---\n\n`278-282`: **LGTM!**\n\nCleanup logic mirrors the v2 function correctly.\n\n</blockquote></details>\n<details>\n<summary>.coderabbit.yaml (1)</summary><blockquote>\n\n`1-44`: **LGTM!**\n\nConfiguration is well-structured and all values conform to the CodeRabbit schema. The path filters appropriately exclude generated and vendored files.\n\n</blockquote></details>\n<details>\n<summary>opc/scripts/core/db/embedding_service.py (1)</summary><blockquote>\n\n`632-635`: **LGTM!**\n\nIntegration follows the established pattern for other providers.\n\n</blockquote></details>\n<details>\n<summary>opc/scripts/setup/wizard.py (3)</summary><blockquote>\n\n`380-418`: **LGTM!**\n\nWell-structured embedding provider configuration with clear user prompts, appropriate defaults, and helpful warnings when API keys are missing. Using `password=True` for API key inputs is a good security practice.\n\n---\n\n`492-516`: **LGTM!**\n\nEnvironment variable generation correctly handles each provider's specific configuration. Commented placeholders for missing API keys help users complete the setup later.\n\n---\n\n`633-649`: **LGTM!**\n\nGood integration of embedding configuration into the wizard flow. Defaulting to \"local\" provider when skipped ensures the setup works without additional configuration.\n\n</blockquote></details>\n\n</blockquote></details>\n\n<sub>‚úèÔ∏è Tip: You can disable this entire section by setting `review_details` to `false` in your review settings.</sub>\n\n</details>\n\n<!-- This is an auto-generated comment by CodeRabbit for review status -->",
    "state": "COMMENTED",
    "html_url": "https://github.com/marcodelpin/Continuous-Claude-v3/pull/10#pullrequestreview-3661367246",
    "pull_request_url": "https://api.github.com/repos/marcodelpin/Continuous-Claude-v3/pulls/10",
    "author_association": "NONE",
    "_links": {
      "html": {
        "href": "https://github.com/marcodelpin/Continuous-Claude-v3/pull/10#pullrequestreview-3661367246"
      },
      "pull_request": {
        "href": "https://api.github.com/repos/marcodelpin/Continuous-Claude-v3/pulls/10"
      }
    },
    "submitted_at": "2026-01-14T15:36:17Z",
    "commit_id": "42975f82f087e8b55625df6ff268a9f7664cfc94"
  }
]
