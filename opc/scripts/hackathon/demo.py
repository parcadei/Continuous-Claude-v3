#!/usr/bin/env python3
"""End-to-end hackathon demo.

Shows all sponsor integrations working together.

Usage:
    python -m scripts.hackathon.demo
"""

import asyncio
import os


async def demo():
    """Run the full demo."""
    print("=" * 60)
    print("CCv3 Hackathon Demo")
    print("Continuous Context Engineering for Real Codebases")
    print("=" * 60)

    # Check environment
    print("\nüìã Checking environment...")
    env_status = {
        "MONGODB_URI": bool(os.environ.get("MONGODB_URI")),
        "FIREWORKS_API_KEY": bool(os.environ.get("FIREWORKS_API_KEY")),
        "JINA_API_KEY": bool(os.environ.get("JINA_API_KEY")),
    }

    for key, status in env_status.items():
        print(f"  {key}: {'‚úì' if status else '‚úó'}")

    # =========================================================================
    # 1. Embeddings (Jina v3)
    # =========================================================================
    print("\n" + "-" * 60)
    print("1Ô∏è‚É£  JINA EMBEDDINGS V3")
    print("-" * 60)

    from scripts.hackathon.embeddings import Embedder

    embedder = Embedder()
    print(f"Provider: {embedder._provider}")

    # Demo task-specific embeddings
    query = "How do I implement vector search?"
    doc = "MongoDB Atlas provides native vector search with hybrid capabilities."

    query_emb = await embedder.embed(query, task="retrieval.query")
    doc_emb = await embedder.embed(doc, task="retrieval.passage")

    print(f"Query embedding ({len(query_emb)} dims): [{query_emb[0]:.4f}, {query_emb[1]:.4f}, ...]")
    print(f"Doc embedding ({len(doc_emb)} dims): [{doc_emb[0]:.4f}, {doc_emb[1]:.4f}, ...]")

    # =========================================================================
    # 2. MongoDB Atlas (Hybrid Search)
    # =========================================================================
    print("\n" + "-" * 60)
    print("2Ô∏è‚É£  MONGODB ATLAS (Hybrid Search with RRF)")
    print("-" * 60)

    if os.environ.get("MONGODB_URI"):
        from scripts.hackathon.mongo_client import MongoClient

        client = MongoClient()
        await client.connect()

        # Store some learnings
        learnings = [
            "MongoDB Atlas Vector Search enables semantic search over embeddings",
            "Hybrid search combines BM25 text matching with vector similarity",
            "Reciprocal Rank Fusion (RRF) merges rankings from multiple sources",
            "Fireworks AI provides 4x faster inference than alternatives",
            "Jina embeddings v3 supports task-specific LoRA adapters",
        ]

        print("Storing learnings...")
        for text in learnings:
            emb = await embedder.embed(text)
            await client.store(text, embedding=emb, metadata={"demo": True})
        print(f"‚úì Stored {len(learnings)} documents with embeddings")

        # Hybrid search demo
        search_query = "vector search performance"
        search_emb = await embedder.embed(search_query, task="retrieval.query")

        results = await client.hybrid_search(search_query, search_emb, limit=3)
        print(f"\nHybrid search for: '{search_query}'")
        for i, r in enumerate(results, 1):
            print(f"  {i}. {r['content'][:60]}...")
            print(f"     RRF Score: {r.get('rrf_score', 0):.4f}")

        await client.close()
    else:
        print("‚ö† MONGODB_URI not set, skipping Atlas demo")

    # =========================================================================
    # 3. Fireworks AI (LLM Inference)
    # =========================================================================
    print("\n" + "-" * 60)
    print("3Ô∏è‚É£  FIREWORKS AI (Fast LLM Inference)")
    print("-" * 60)

    if os.environ.get("FIREWORKS_API_KEY"):
        from scripts.hackathon.inference import LLM

        llm = LLM(model="fast")
        print(f"Model: {llm.model}")

        # Simple completion
        response = await llm.chat(
            "Explain in one sentence what makes MongoDB Atlas good for AI apps.",
            system="You are a concise technical writer.",
        )
        print(f"\nChat response:\n  {response}")

        # Function calling
        result = await llm.call_function(
            "Store a new learning about vector databases",
            functions=[{
                "name": "store_learning",
                "description": "Store a learning in the knowledge base",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "content": {"type": "string", "description": "The learning content"},
                        "tags": {"type": "array", "items": {"type": "string"}},
                    },
                    "required": ["content"],
                },
            }],
        )
        print(f"\nFunction calling result:\n  {result}")

        await llm.close()
    else:
        print("‚ö† FIREWORKS_API_KEY not set, skipping inference demo")

    # =========================================================================
    # 4. Quality Gate (Galileo-style)
    # =========================================================================
    print("\n" + "-" * 60)
    print("4Ô∏è‚É£  QUALITY GATE (Eval Before Commit)")
    print("-" * 60)

    from scripts.hackathon.eval_gate import QualityGate

    gate = QualityGate()

    # Simulate eval gate on LLM output
    test_input = "What are the benefits of hybrid search?"
    test_output = "Hybrid search combines keyword matching with semantic understanding. This provides better recall than pure keyword search and better precision than pure vector search. MongoDB Atlas implements this using BM25 and vector similarity with RRF fusion."
    test_context = "Hybrid search merges BM25 text and vector similarity."

    result = await gate.check(test_input, test_output, test_context)

    print(f"Input: {test_input}")
    print(f"Output: {test_output[:80]}...")
    print(f"\nEval Result:")
    print(f"  Passed: {'‚úì' if result.passed else '‚úó'}")
    print(f"  Scores: {result.scores}")
    if result.failed_metrics:
        print(f"  Failed: {result.failed_metrics}")

    # =========================================================================
    # Summary
    # =========================================================================
    print("\n" + "=" * 60)
    print("DEMO COMPLETE")
    print("=" * 60)
    print("""
Sponsors demonstrated:
  ‚úì MongoDB Atlas - Hybrid search with RRF
  ‚úì Jina AI - Task-specific embeddings (v3)
  ‚úì Fireworks AI - Fast LLM inference + function calling
  ‚úì Galileo-style - Quality gate evaluation

Key innovation: Context engineering, not prompt engineering
  - 95% token savings via TLDR (23k ‚Üí 1.2k)
  - Structured handoff packs
  - Compounding sessions
""")

    await embedder.close()


if __name__ == "__main__":
    asyncio.run(demo())
